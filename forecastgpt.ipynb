{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bb3ce4",
   "metadata": {},
   "source": [
    "# AWS Marketplace Product Usage Demonstration - Multivariate ForecastGPT Model Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf1ff7",
   "metadata": {},
   "source": [
    "## ForecastGPT\n",
    "\n",
    "This sample notebook demonstrates the usage of the ForecastGPT.\n",
    "\n",
    "This solution is multivariate forecasting model to forecast data from a sample input data.\n",
    "\n",
    "This sample notebook shows you how to deploy Multivariate forecast model using Amazon SageMaker.\n",
    "\n",
    "**Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Car Mileage Predictor. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](# Subscribe-to-the-model-package)\n",
    "2. [Set up the environment](# Setup the environment)\n",
    "3. [Create the session](# Create the session)\n",
    "4. [Create Model](# Create model)\n",
    "5. [Create an endpoint and perform real-time inference](#-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "6. [Perform batch inference](# Perform-batch-inference)\n",
    "    1. [Configure the input S3 bucket folder](# A. -Configure the input S3 bucket folder)\n",
    "    2. [Deploy the model](# B. -Deploy the model)\n",
    "    3. [Download the file from output S3 bucket folder](# C. -Download the file from output S3 bucket folder)\n",
    "    4. [Visualize data](# D. -Visualize data)\n",
    "7. [Clean-up](# Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d33eb",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8094c0c",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page Car Mileage Predictor. \n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3512616",
   "metadata": {},
   "source": [
    "## 2. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea90e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefixes\n",
    "common_prefix = \"<your s3 bucket name>\"\n",
    "batch_inference_input_prefix = \"forecastgpt/input\"\n",
    "batch_inference_output_prefix = \"forecastgpt/output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff55c1",
   "metadata": {},
   "source": [
    "## 3. Create the session\n",
    "\n",
    "The session remembers our connection parameters to Amazon SageMaker. We'll use it to perform all of our Amazon SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b061768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650785a",
   "metadata": {},
   "source": [
    "## 4. Create Model\n",
    "\n",
    "Now we use the above Model Package to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b48a394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = '<your model package arn>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32346e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'forecastgpt'\n",
    "\n",
    "content_type = 'application/json'\n",
    "\n",
    "real_time_inference_instance_type = 'ml.m4.4xlarge' \n",
    "\n",
    "batch_transform_inference_instance_type = 'ml.m4.4xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a681e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.Predictor(endpoint, session, content_type)\n",
    "\n",
    "# Create a deployable model from the model package\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls = predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3c0cad",
   "metadata": {},
   "source": [
    "## 5. Create-an-endpoint-and-perform-real-time-inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52584566",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cf11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "#Deploy the model\n",
    "predictor = model.deploy(1,real_time_inference_instance_type,endpoint_name = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797eb9c",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34a33d",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f3804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'input/ett.json' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7748e3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': {'0': '2016-07-01 00:00:00',\n",
       "  '1': '2016-07-01 01:00:00',\n",
       "  '2': '2016-07-01 02:00:00',\n",
       "  '3': '2016-07-01 03:00:00',\n",
       "  '4': '2016-07-01 04:00:00',\n",
       "  '5': '2016-07-01 05:00:00',\n",
       "  '6': '2016-07-01 06:00:00',\n",
       "  '7': '2016-07-01 07:00:00',\n",
       "  '8': '2016-07-01 08:00:00',\n",
       "  '9': '2016-07-01 09:00:00',\n",
       "  '10': '2016-07-01 10:00:00',\n",
       "  '11': '2016-07-01 11:00:00',\n",
       "  '12': '2016-07-01 12:00:00',\n",
       "  '13': '2016-07-01 13:00:00',\n",
       "  '14': '2016-07-01 14:00:00'},\n",
       " 'HUFL': {'0': 5.8270001411,\n",
       "  '1': 5.6929998398,\n",
       "  '2': 5.1570000648,\n",
       "  '3': 5.0900001526,\n",
       "  '4': 5.3579998016,\n",
       "  '5': 5.6259999275,\n",
       "  '6': 7.1669998169,\n",
       "  '7': 7.4349999428,\n",
       "  '8': 5.5590000153,\n",
       "  '9': 4.5549998283,\n",
       "  '10': 4.9569997787,\n",
       "  '11': 5.7600002289,\n",
       "  '12': 4.6890001297,\n",
       "  '13': 4.6890001297,\n",
       "  '14': 5.0900001526},\n",
       " 'HULL': {'0': 2.0090000629,\n",
       "  '1': 2.0759999752,\n",
       "  '2': 1.7410000563,\n",
       "  '3': 1.9420000315,\n",
       "  '4': 1.9420000315,\n",
       "  '5': 2.1429998875,\n",
       "  '6': 2.9470000267,\n",
       "  '7': 3.2820000648,\n",
       "  '8': 3.013999939,\n",
       "  '9': 2.5450000763,\n",
       "  '10': 2.5450000763,\n",
       "  '11': 2.5450000763,\n",
       "  '12': 2.5450000763,\n",
       "  '13': 2.6789999008,\n",
       "  '14': 2.9470000267},\n",
       " 'MUFL': {'0': 1.5989999771,\n",
       "  '1': 1.4919999838,\n",
       "  '2': 1.2790000439,\n",
       "  '3': 1.2790000439,\n",
       "  '4': 1.4919999838,\n",
       "  '5': 1.5279999971,\n",
       "  '6': 2.1319999695,\n",
       "  '7': 2.3099999428,\n",
       "  '8': 2.4519999027,\n",
       "  '9': 1.9190000296,\n",
       "  '10': 1.9900000095,\n",
       "  '11': 2.2030000687,\n",
       "  '12': 1.8120000362,\n",
       "  '13': 1.7769999504,\n",
       "  '14': 2.4519999027},\n",
       " 'MULL': {'0': 0.4620000124,\n",
       "  '1': 0.425999999,\n",
       "  '2': 0.3549999893,\n",
       "  '3': 0.3910000026,\n",
       "  '4': 0.4620000124,\n",
       "  '5': 0.5329999924,\n",
       "  '6': 0.7820000052,\n",
       "  '7': 1.0310000181,\n",
       "  '8': 1.1729999781,\n",
       "  '9': 0.8169999719,\n",
       "  '10': 0.8529999852,\n",
       "  '11': 0.8529999852,\n",
       "  '12': 0.8529999852,\n",
       "  '13': 1.243999958,\n",
       "  '14': 1.3500000238},\n",
       " 'LUFL': {'0': 4.2030000687,\n",
       "  '1': 4.1420001984,\n",
       "  '2': 3.7769999504,\n",
       "  '3': 3.8069999218,\n",
       "  '4': 3.8680000305,\n",
       "  '5': 4.0510001183,\n",
       "  '6': 5.0260000229,\n",
       "  '7': 5.0869998932,\n",
       "  '8': 2.9549999237,\n",
       "  '9': 2.6800000668,\n",
       "  '10': 2.9549999237,\n",
       "  '11': 3.4419999123,\n",
       "  '12': 2.8329999447,\n",
       "  '13': 3.1070001125,\n",
       "  '14': 2.5590000153},\n",
       " 'LULL': {'0': 1.3400000334,\n",
       "  '1': 1.3710000515,\n",
       "  '2': 1.2180000544,\n",
       "  '3': 1.2790000439,\n",
       "  '4': 1.2790000439,\n",
       "  '5': 1.3710000515,\n",
       "  '6': 1.8580000401,\n",
       "  '7': 2.2239999771,\n",
       "  '8': 1.432000041,\n",
       "  '9': 1.3710000515,\n",
       "  '10': 1.4919999838,\n",
       "  '11': 1.4919999838,\n",
       "  '12': 1.5230000019,\n",
       "  '13': 1.6139999628,\n",
       "  '14': 1.432000041},\n",
       " 'OT': {'0': 30.5310001373,\n",
       "  '1': 27.7870006561,\n",
       "  '2': 27.7870006561,\n",
       "  '3': 25.0440006256,\n",
       "  '4': 21.9479999542,\n",
       "  '5': 21.1739997864,\n",
       "  '6': 22.7919998169,\n",
       "  '7': 23.1439990997,\n",
       "  '8': 21.6669998169,\n",
       "  '9': 17.4459991455,\n",
       "  '10': 19.9790000916,\n",
       "  '11': 20.1189994812,\n",
       "  '12': 19.2049999237,\n",
       "  '13': 18.5720005035,\n",
       "  '14': 19.5559997559}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_name, 'r') as f:\n",
    "    data = json.load(f)\n",
    "#data=json.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaccf2b",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e839140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/json\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $model_name \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07715c6a",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a19b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.131582736968994,\n",
       "  2.957359790802002,\n",
       "  2.3567450046539307,\n",
       "  1.3344697952270508,\n",
       "  2.841761589050293,\n",
       "  1.5155383348464966,\n",
       "  19.937015533447266],\n",
       " [5.1317620277404785,\n",
       "  2.9284403324127197,\n",
       "  2.3371293544769287,\n",
       "  1.2956286668777466,\n",
       "  2.82720947265625,\n",
       "  1.4990074634552002,\n",
       "  19.59956169128418],\n",
       " [5.163863658905029,\n",
       "  2.878535032272339,\n",
       "  2.3105084896087646,\n",
       "  1.2562291622161865,\n",
       "  2.8217320442199707,\n",
       "  1.4863511323928833,\n",
       "  19.501346588134766],\n",
       " [5.056051254272461,\n",
       "  2.8135616779327393,\n",
       "  2.2357633113861084,\n",
       "  1.1918236017227173,\n",
       "  2.7262022495269775,\n",
       "  1.4806846380233765,\n",
       "  18.788660049438477],\n",
       " [5.114974498748779,\n",
       "  2.787313938140869,\n",
       "  2.2219409942626953,\n",
       "  1.128020167350769,\n",
       "  2.8188819885253906,\n",
       "  1.4553855657577515,\n",
       "  19.4351863861084],\n",
       " [5.121236801147461,\n",
       "  2.726931095123291,\n",
       "  2.1498310565948486,\n",
       "  1.096701741218567,\n",
       "  2.8770666122436523,\n",
       "  1.473987340927124,\n",
       "  19.699953079223633],\n",
       " [5.074916362762451,\n",
       "  2.624584436416626,\n",
       "  2.071563482284546,\n",
       "  1.0045452117919922,\n",
       "  2.853257656097412,\n",
       "  1.4548814296722412,\n",
       "  19.4008731842041],\n",
       " [5.112423419952393,\n",
       "  2.621086597442627,\n",
       "  2.0579771995544434,\n",
       "  0.9823586940765381,\n",
       "  2.911076784133911,\n",
       "  1.4572136402130127,\n",
       "  19.877771377563477],\n",
       " [5.176373481750488,\n",
       "  2.5822057723999023,\n",
       "  2.035836696624756,\n",
       "  0.9493001699447632,\n",
       "  3.0553138256073,\n",
       "  1.4643480777740479,\n",
       "  20.499019622802734],\n",
       " [5.517465114593506,\n",
       "  2.677802085876465,\n",
       "  2.1230599880218506,\n",
       "  0.994385838508606,\n",
       "  3.4097390174865723,\n",
       "  1.5019272565841675,\n",
       "  22.810848236083984],\n",
       " [5.424866199493408,\n",
       "  2.615006685256958,\n",
       "  2.0409862995147705,\n",
       "  0.9401148557662964,\n",
       "  3.4128541946411133,\n",
       "  1.4924373626708984,\n",
       "  23.111555099487305],\n",
       " [5.2037835121154785,\n",
       "  2.48740291595459,\n",
       "  1.9317985773086548,\n",
       "  0.8820011615753174,\n",
       "  3.2558224201202393,\n",
       "  1.411183476448059,\n",
       "  22.0922908782959],\n",
       " [5.221508502960205,\n",
       "  2.4733681678771973,\n",
       "  1.9112095832824707,\n",
       "  0.849526584148407,\n",
       "  3.225292682647705,\n",
       "  1.4259644746780396,\n",
       "  21.555965423583984],\n",
       " [5.264649868011475,\n",
       "  2.5266735553741455,\n",
       "  1.8966666460037231,\n",
       "  0.8730061054229736,\n",
       "  3.3426570892333984,\n",
       "  1.4820748567581177,\n",
       "  20.751190185546875],\n",
       " [5.484667778015137,\n",
       "  2.567098379135132,\n",
       "  1.9764107465744019,\n",
       "  0.8737490177154541,\n",
       "  3.430452346801758,\n",
       "  1.49561607837677,\n",
       "  20.400333404541016],\n",
       " [5.745619297027588,\n",
       "  2.794095277786255,\n",
       "  2.1199116706848145,\n",
       "  0.9845334887504578,\n",
       "  3.622070074081421,\n",
       "  1.6302707195281982,\n",
       "  21.444011688232422]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "with open('output.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i,v in data.items():\n",
    "    if i=='result':\n",
    "        result=v\n",
    "result   # forecasted output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0a24a",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d66e1",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "306e84aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: forecastgpt\n",
      "INFO:sagemaker:Deleting endpoint with name: forecastgpt\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5320447",
   "metadata": {},
   "source": [
    "## 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ef8ee",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc50238",
   "metadata": {},
   "source": [
    "### A. Configure the input S3 bucket folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "249cf7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_input_folder = 'input'\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder,common_prefix,batch_inference_input_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c860706",
   "metadata": {},
   "source": [
    "### B. Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84662894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: ForecastGPT-2024-09-27-13-57-18-464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[34mStarting the inference server with 16 workers.\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [10] [INFO] Starting gunicorn 23.0.0\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [96] [INFO] Booting worker with pid: 96\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [127] [INFO] Booting worker with pid: 127\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [143] [INFO] Booting worker with pid: 143\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [144] [INFO] Booting worker with pid: 144\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [145] [INFO] Booting worker with pid: 145\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:41 +0000] [146] [INFO] Booting worker with pid: 146\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:41 +0000] [147] [INFO] Booting worker with pid: 147\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:41 +0000] [163] [INFO] Booting worker with pid: 163\u001b[0m\n",
      "\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,446 ] 55 root - INFO - Data Preprocessed\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,446 ] 46 root - INFO - Data Padded\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,447 ] 34 root - INFO - Forecast Sequence Created: (96, 7)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,446 ] 55 root - INFO - Data Preprocessed\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,446 ] 46 root - INFO - Data Padded\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,447 ] 34 root - INFO - Forecast Sequence Created: (96, 7)\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,447 ] 84 root - INFO - Data Reading Complete\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,447 ] 84 root - INFO - Data Reading Complete\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,496 ] 50 root - INFO - Model Loaded\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,496 ] 50 root - INFO - Model Loaded\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,496 ] 64 root - INFO - Model Input Prepared. Shape: torch.Size([1, 96, 7])\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,496 ] 74 root - INFO - Running Forecast\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,531 ] 94 root - INFO - Forecast Completed: (16, 7)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2024:14:02:52 +0000] \"POST /invocations HTTP/1.1\" 200 2282 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,496 ] 64 root - INFO - Model Input Prepared. Shape: torch.Size([1, 96, 7])\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,496 ] 74 root - INFO - Running Forecast\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,531 ] 94 root - INFO - Forecast Completed: (16, 7)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2024:14:02:52 +0000] \"POST /invocations HTTP/1.1\" 200 2282 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-09-27T14:02:49.361:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mStarting the inference server with 16 workers.\u001b[0m\n",
      "\u001b[35mStarting the inference server with 16 workers.\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [10] [INFO] Starting gunicorn 23.0.0\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [96] [INFO] Booting worker with pid: 96\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [127] [INFO] Booting worker with pid: 127\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [143] [INFO] Booting worker with pid: 143\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [144] [INFO] Booting worker with pid: 144\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:40 +0000] [145] [INFO] Booting worker with pid: 145\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:41 +0000] [146] [INFO] Booting worker with pid: 146\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:41 +0000] [147] [INFO] Booting worker with pid: 147\u001b[0m\n",
      "\u001b[34m[2024-09-27 14:02:41 +0000] [163] [INFO] Booting worker with pid: 163\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [10] [INFO] Starting gunicorn 23.0.0\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [96] [INFO] Booting worker with pid: 96\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [127] [INFO] Booting worker with pid: 127\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [143] [INFO] Booting worker with pid: 143\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [144] [INFO] Booting worker with pid: 144\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:40 +0000] [145] [INFO] Booting worker with pid: 145\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:41 +0000] [146] [INFO] Booting worker with pid: 146\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:41 +0000] [147] [INFO] Booting worker with pid: 147\u001b[0m\n",
      "\u001b[35m[2024-09-27 14:02:41 +0000] [163] [INFO] Booting worker with pid: 163\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,446 ] 55 root - INFO - Data Preprocessed\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,446 ] 46 root - INFO - Data Padded\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,447 ] 34 root - INFO - Forecast Sequence Created: (96, 7)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2024:14:02:49 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,446 ] 55 root - INFO - Data Preprocessed\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,446 ] 46 root - INFO - Data Padded\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,447 ] 34 root - INFO - Forecast Sequence Created: (96, 7)\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:49,447 ] 84 root - INFO - Data Reading Complete\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:49,447 ] 84 root - INFO - Data Reading Complete\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,496 ] 50 root - INFO - Model Loaded\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,496 ] 50 root - INFO - Model Loaded\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,496 ] 64 root - INFO - Model Input Prepared. Shape: torch.Size([1, 96, 7])\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,496 ] 74 root - INFO - Running Forecast\u001b[0m\n",
      "\u001b[34m[ 2024-09-27 14:02:52,531 ] 94 root - INFO - Forecast Completed: (16, 7)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2024:14:02:52 +0000] \"POST /invocations HTTP/1.1\" 200 2282 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,496 ] 64 root - INFO - Model Input Prepared. Shape: torch.Size([1, 96, 7])\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,496 ] 74 root - INFO - Running Forecast\u001b[0m\n",
      "\u001b[35m[ 2024-09-27 14:02:52,531 ] 94 root - INFO - Forecast Completed: (16, 7)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2024:14:02:52 +0000] \"POST /invocations HTTP/1.1\" 200 2282 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-09-27T14:02:49.361:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(1,batch_transform_inference_instance_type,output_path=\"s3://\"+common_prefix+\"/\"+batch_inference_output_prefix+\"/\")\n",
    "transformer.transform(transform_input,content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8388de",
   "metadata": {},
   "source": [
    "### C. Download the file from output S3 bucket folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9f8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "with open('output3.json','wb') as f:\n",
    "    s3_conn.download_fileobj(common_prefix,batch_inference_output_prefix+'ett.json.out',f) # ett.json.out = this file will be the same input file name \n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e0d47",
   "metadata": {},
   "source": [
    "### D. Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20f056dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.131582736968994,\n",
       "  2.957359790802002,\n",
       "  2.3567450046539307,\n",
       "  1.3344697952270508,\n",
       "  2.841761589050293,\n",
       "  1.5155383348464966,\n",
       "  19.937015533447266],\n",
       " [5.1317620277404785,\n",
       "  2.9284403324127197,\n",
       "  2.3371293544769287,\n",
       "  1.2956286668777466,\n",
       "  2.82720947265625,\n",
       "  1.4990074634552002,\n",
       "  19.59956169128418],\n",
       " [5.163863658905029,\n",
       "  2.878535032272339,\n",
       "  2.3105084896087646,\n",
       "  1.2562291622161865,\n",
       "  2.8217320442199707,\n",
       "  1.4863511323928833,\n",
       "  19.501346588134766],\n",
       " [5.056051254272461,\n",
       "  2.8135616779327393,\n",
       "  2.2357633113861084,\n",
       "  1.1918236017227173,\n",
       "  2.7262022495269775,\n",
       "  1.4806846380233765,\n",
       "  18.788660049438477],\n",
       " [5.114974498748779,\n",
       "  2.787313938140869,\n",
       "  2.2219409942626953,\n",
       "  1.128020167350769,\n",
       "  2.8188819885253906,\n",
       "  1.4553855657577515,\n",
       "  19.4351863861084],\n",
       " [5.121236801147461,\n",
       "  2.726931095123291,\n",
       "  2.1498310565948486,\n",
       "  1.096701741218567,\n",
       "  2.8770666122436523,\n",
       "  1.473987340927124,\n",
       "  19.699953079223633],\n",
       " [5.074916362762451,\n",
       "  2.624584436416626,\n",
       "  2.071563482284546,\n",
       "  1.0045452117919922,\n",
       "  2.853257656097412,\n",
       "  1.4548814296722412,\n",
       "  19.4008731842041],\n",
       " [5.112423419952393,\n",
       "  2.621086597442627,\n",
       "  2.0579771995544434,\n",
       "  0.9823586940765381,\n",
       "  2.911076784133911,\n",
       "  1.4572136402130127,\n",
       "  19.877771377563477],\n",
       " [5.176373481750488,\n",
       "  2.5822057723999023,\n",
       "  2.035836696624756,\n",
       "  0.9493001699447632,\n",
       "  3.0553138256073,\n",
       "  1.4643480777740479,\n",
       "  20.499019622802734],\n",
       " [5.517465114593506,\n",
       "  2.677802085876465,\n",
       "  2.1230599880218506,\n",
       "  0.994385838508606,\n",
       "  3.4097390174865723,\n",
       "  1.5019272565841675,\n",
       "  22.810848236083984],\n",
       " [5.424866199493408,\n",
       "  2.615006685256958,\n",
       "  2.0409862995147705,\n",
       "  0.9401148557662964,\n",
       "  3.4128541946411133,\n",
       "  1.4924373626708984,\n",
       "  23.111555099487305],\n",
       " [5.2037835121154785,\n",
       "  2.48740291595459,\n",
       "  1.9317985773086548,\n",
       "  0.8820011615753174,\n",
       "  3.2558224201202393,\n",
       "  1.411183476448059,\n",
       "  22.0922908782959],\n",
       " [5.221508502960205,\n",
       "  2.4733681678771973,\n",
       "  1.9112095832824707,\n",
       "  0.849526584148407,\n",
       "  3.225292682647705,\n",
       "  1.4259644746780396,\n",
       "  21.555965423583984],\n",
       " [5.264649868011475,\n",
       "  2.5266735553741455,\n",
       "  1.8966666460037231,\n",
       "  0.8730061054229736,\n",
       "  3.3426570892333984,\n",
       "  1.4820748567581177,\n",
       "  20.751190185546875],\n",
       " [5.484667778015137,\n",
       "  2.567098379135132,\n",
       "  1.9764107465744019,\n",
       "  0.8737490177154541,\n",
       "  3.430452346801758,\n",
       "  1.49561607837677,\n",
       "  20.400333404541016],\n",
       " [5.745619297027588,\n",
       "  2.794095277786255,\n",
       "  2.1199116706848145,\n",
       "  0.9845334887504578,\n",
       "  3.622070074081421,\n",
       "  1.6302707195281982,\n",
       "  21.444011688232422]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "with open('output3.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i,v in data.items():\n",
    "    if i=='result':\n",
    "        result=v\n",
    "result  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be426131",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e8239",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85108030-d429-4949-8de5-dfd80f2bcf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: ForecastGPT-2024-09-27-13-57-17-733\n"
     ]
    }
   ],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8053b",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0ae0e",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
